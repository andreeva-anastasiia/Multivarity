from typing import Dict
import pandas as pd
import numpy as np
from pathlib import Path

def autogluon_performance(train_data:pd.DataFrame, test_data:pd.DataFrame)->dict:
    """
    Evaluate the performance of AutoGluon on the given data
    Args:
        train_data: Training Data
        test_data: Test Data
    Returns: A dictionary with the performance metrics
    """
    # TODO Convert Data to AutoGluon Format
    # TODO Train AutoGluon Model

    raise NotImplementedError("Method not implemented")


# if enough time
def chronos_performance(train_data:pd.DataFrame, test_data:pd.DataFrame)->dict:
    """
    Evaluate the performance of Chronos on the given data
    NOTE: Only works with Univariate Time Series Data for now
    Question to answer is each Component looking realistic enough on their own to aid Chronos' training
    Args:
        train_data: Training Data
        test_data: Test Data
    Returns: A dictionary with the performance metrics
    """
    # TODO Convert Data to Chronos Format
    # TODO Train Chronos Model

    raise NotImplementedError("Method not implemented")

# real_world_data["train"][0]["value"][0]

def season_discriminator_loss(generated_data:pd.DataFrame, test_data:pd.DataFrame, season_discriminator_path: Path)->dict:
    """
    Evaluate the performance of Chronos on the given data
    NOTE: Only works with Univariate Time Series Data for now
    Args:
        generated_data: Data generated by the method ~ can it fool the discriminator
        test_data: Real World Data serves as baseline
        season_discriminator_path: Path to the pretrained Season Discriminator File
    Returns: A dictionary with the performance metrics
    """
    # TODO Load Discriminator Model from path
    # TODO Extract Seasons from Data



    # TODO Let Discriminator make predictions on generated data
    # TODO Let Discriminator make predictions on test data
    # Idealy it will predict that both consist to large parts of real data 
    # TODO return results

    raise NotImplementedError("Method not implemented")


def statistical_similarity(generated_data:pd.DataFrame, test_data:pd.DataFrame)->dict:
    """
    Evaluate the statistical similarity of the generated data to the real data
    """
    results = {}

    # Check if test_data needs alignment
    if isinstance(test_data, pd.Series) and isinstance(test_data.iloc[0], list):  # If it's a series of lists
        values = test_data.iloc[0]  # Extract the list of values
        test_data = pd.DataFrame({
            0: values,
            'time': range(len(values))  # Generate a time index
        })

    # Ensure the 'generated_data' and 'test_data' DataFrames have the same structure
    if 'time' not in generated_data.columns:
        generated_data['time'] = range(len(generated_data))  # Add time column if missing

    # TODO Compare Distributions of means, variances, skewness, etc.


    # TODO Add each value to results
    # mmd = maximum_mean_discrepancy(generated_data, test_data)
    # results['mmd'] = mmd


    corr_mat = correlation_matrix(generated_data, test_data)


    # TODO Reduce matrices to a single value
    # corr_value = None
    results['corr_mat'] = corr_mat


    # TODO Auto Correlation
    # TODO Seasonal Patterns
    raise NotImplementedError("Method not implemented")


# def maximum_mean_discrepancy(generated_data:pd.DataFrame, test_data:pd.DataFrame)->dict:
#     """
#     Evaluate the Maximum Mean Discrepancy between the real and generated data
#     """
#     # TODO Implement
#
#     raise NotImplementedError("Method not implemented")


def maximum_mean_discrepancy(
        generated_data: pd.DataFrame, test_data: pd.DataFrame, kernel: str = 'rbf', gamma: float = 1.0
) -> float:
    """
    Evaluate the Maximum Mean Discrepancy between the real and generated data.

    Parameters:
    - generated_data: pd.DataFrame, the generated data.
    - test_data: pd.DataFrame, the test (real-world) data.
    - kernel: The type of kernel to use (default: 'rbf').
    - gamma: Parameter for the RBF kernel.

    Returns:
    - mmd: A float representing the Maximum Mean Discrepancy score.
    """
    # Ensure data are NumPy arrays
    X = generated_data.to_numpy()
    Y = test_data.to_numpy()

    # Compute kernel matrices
    K_XX = kernel_function(X, X, kernel=kernel, gamma=gamma)  # Kernel between generated data
    K_YY = kernel_function(Y, Y, kernel=kernel, gamma=gamma)  # Kernel between test data
    K_XY = kernel_function(X, Y, kernel=kernel, gamma=gamma)  # Kernel between generated and test data

    # Number of samples in each dataset
    n_X = X.shape[0]
    n_Y = Y.shape[0]

    # Compute MMD score
    mmd = (np.sum(K_XX) / (n_X * n_X) +
           np.sum(K_YY) / (n_Y * n_Y) -
           2 * np.sum(K_XY) / (n_X * n_Y))

    return mmd


def kernel_function(X1: np.ndarray, X2: np.ndarray, kernel: str = 'rbf', gamma: float = 1.0) -> np.ndarray:
    """
    Compute the kernel matrix for given data matrices X1 and X2.

    Parameters:
    - X1, X2: Arrays of shape (n_samples1, n_features) and (n_samples2, n_features).
    - kernel: The type of kernel to compute. Supported: 'rbf'.
    - gamma: Parameter for the RBF kernel.

    Returns:
    - K: Kernel matrix of shape (n_samples1, n_samples2).
    """
    if kernel == 'rbf':
        # Compute pairwise squared Euclidean distances
        sq_dists = (
            np.sum(X1**2, axis=1).reshape(-1, 1)
            + np.sum(X2**2, axis=1)
            - 2 * np.dot(X1, X2.T)
        )
        # Compute the RBF kernel matrix
        K = np.exp(-gamma * sq_dists)
    else:
        raise ValueError(f"Unsupported kernel type: {kernel}")

    return K

#
# def correlation_matrix(generated_data:pd.DataFrame, test_data:pd.DataFrame)->dict:
#     """
#     Evaluate the Correlation Matrix between the real and generated data
#     """
#     # TODO Implement
#     raise NotImplementedError("Method not implemented")


def correlation_matrix(generated_data: pd.DataFrame, test_data: pd.DataFrame) -> dict:
    """
    Compare the correlation between generated_data and test_data.
    """
    results = {}

    # Check if test_data needs alignment
    if isinstance(test_data, pd.Series) and isinstance(test_data.iloc[0], list):  # If it's a series of lists
        values = test_data.iloc[0]  # Extract the list of values
        test_data = pd.DataFrame({
            0: values,
            'time': range(len(values))  # Generate a time index
        })

    # Ensure the 'generated_data' and 'test_data' DataFrames have the same structure
    if 'time' not in generated_data.columns:
        generated_data['time'] = range(len(generated_data))  # Add time column if missing

    # Correlation matrices
    corr_test = test_data.corr()  # Correlation matrix for test data
    corr_generated = generated_data.corr()  # Correlation matrix for generated data

    results['corr_test'] = corr_test
    results['corr_generated'] = corr_generated

    # Compare the correlation matrices using Frobenius norm
    if corr_test.shape == corr_generated.shape:
        difference = corr_test.values - corr_generated.values
        frobenius_norm = np.linalg.norm(difference, 'fro')
        results['similarity_score'] = 1 / (1 + frobenius_norm)  # Convert to similarity score (lower is better)
    else:
        results['similarity_score'] = None
        print("Warning: Real and generated data have different dimensions; skipping similarity comparison.")

    # Return the correlation matrices and the similarity score
    return results






